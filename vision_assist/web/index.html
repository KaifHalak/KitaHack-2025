<!DOCTYPE html>
<html>
  <head>
    <base href="$FLUTTER_BASE_HREF" />

    <meta charset="UTF-8" />
    <meta content="IE=Edge" http-equiv="X-UA-Compatible" />
    <meta name="description" content="A vision assistance app for visually impaired users." />

    <!-- iOS meta tags & icons -->
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="apple-mobile-web-app-title" content="vision_assist" />
    <link rel="apple-touch-icon" href="icons/Icon-192.png" />

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="favicon.png" />

    <title>Vision Assist</title>
    <link rel="manifest" href="manifest.json" />

    <!-- Load Google Maps JavaScript API -->
    <script>
      // Function to load Google Maps with API key from environment
      function loadGoogleMaps() {
        // Get API key - will be set by Dart code
        const apiKey = window.MAPS_API_KEY || '';
        
        if (!apiKey || apiKey === 'MAPS_API_KEY_PLACEHOLDER') {
          console.error('Invalid Google Maps API key');
          return;
        }
        
        console.log('Loading Google Maps with API key:', apiKey.substring(0, 4) + '...');
        
        // Remove any existing Google Maps script tags
        const existingScripts = document.querySelectorAll('script[src*="maps.googleapis.com"]');
        existingScripts.forEach(script => script.remove());
        
        const script = document.createElement('script');
        script.src = `https://maps.googleapis.com/maps/api/js?key=${apiKey}&libraries=places,geometry&loading=async&callback=initMap`;
        script.async = true;
        script.defer = true;
        document.head.appendChild(script);
      }
      
      // Initialize a global placeholder that will be replaced by Dart code
      window.MAPS_API_KEY = '';
      
      // Wait for Dart to set the API key, then load the map
      let checkApiKeyInterval = setInterval(() => {
        if (window.MAPS_API_KEY && window.MAPS_API_KEY !== 'MAPS_API_KEY_PLACEHOLDER') {
          clearInterval(checkApiKeyInterval);
          loadGoogleMaps();
        }
      }, 500);
      
      setTimeout(() => {
        clearInterval(checkApiKeyInterval);
        if (!window.MAPS_API_KEY || window.MAPS_API_KEY === 'MAPS_API_KEY_PLACEHOLDER') {
          console.error('Timed out waiting for Maps API key');
        }
      }, 10000); // Timeout after 10 seconds
    </script>
    
    <style>
      #map-container {
        position: fixed;
        bottom: 20px;
        right: 20px;
        width: 300px;
        height: 200px;
        z-index: 1;
        border-radius: 8px;
        overflow: hidden;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
      }
      #map {
        width: 100%;
        height: 100%;
      }
      #flutter_target {
        position: relative;
        z-index: 2;
      }
    </style>

    <!-- Load TensorFlow.js and COCO-SSD model before the Flutter-related scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="object_detector.js"></script>

    <!-- Audio feedback helper -->
    <script>
      // Text-to-speech utility
      const speechSynthesis = window.speechSynthesis;
      let speakingQueue = [];
      let isSpeaking = false;
      let audioEnabled = true;
      let geminiAudioPlaying = false;

      // Toggle audio on/off
      window.toggleAudio = function (enabled) {
        audioEnabled = enabled;

        if (!enabled) {
          // Cancel any ongoing speech
          speechSynthesis.cancel();
          speakingQueue = [];
          isSpeaking = false;
          geminiAudioPlaying = false;
        } else {
          // Announce that audio is enabled
          window.speakText("Audio feedback enabled", true);
        }
      };

      // Check if Gemini audio is currently playing
      window.isGeminiAudioPlaying = function() {
        return geminiAudioPlaying;
      };

      // Speak text with specified options
      window.speakText = function (
        text,
        priority = false,
        rate = 1.0,
        pitch = 1.0
      ) {
        if (!text || !audioEnabled) return;

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = rate;
        utterance.pitch = pitch;
        
        // Use a more natural voice if available
        try {
          const voices = speechSynthesis.getVoices();
          // Try to find a good quality female voice
          const preferredVoices = [
            "Google US English Female",
            "Microsoft Zira - English (United States)",
            "Samantha",
            "Karen"
          ];
          
          let selectedVoice = null;
          
          // First try to find one of our preferred voices
          for (const prefVoice of preferredVoices) {
            selectedVoice = voices.find(v => v.name === prefVoice);
            if (selectedVoice) break;
          }
          
          // If no preferred voice found, try to find any female US English voice
          if (!selectedVoice) {
            selectedVoice = voices.find(v => 
              v.name.includes("Female") && 
              (v.lang === "en-US" || v.lang === "en_US")
            );
          }
          
          // If we found a better voice, use it
          if (selectedVoice) {
            utterance.voice = selectedVoice;
          }
        } catch (e) {
          console.log("Error setting voice:", e);
        }

        // If priority message, cancel current speech and speak immediately
        if (priority) {
          speechSynthesis.cancel();
          speakingQueue = [];
          speechSynthesis.speak(utterance);
          return;
        }

        // Add to queue
        speakingQueue.push(utterance);

        // Process queue if not already speaking
        if (!isSpeaking) {
          processQueue();
        }
      };

      // Process the speaking queue
      function processQueue() {
        if (speakingQueue.length === 0) {
          isSpeaking = false;
          return;
        }

        isSpeaking = true;
        const utterance = speakingQueue.shift();

        utterance.onend = () => {
          setTimeout(() => processQueue(), 100); // Small delay between messages
        };

        speechSynthesis.speak(utterance);
      }

      // Get direction relative to camera center (left, right, center)
      window.getRelativeDirection = function (objectX, frameWidth) {
        const centerX = frameWidth / 2;
        const threshold = frameWidth * 0.2; // 20% of frame width

        if (objectX < centerX - threshold) {
          return "left";
        } else if (objectX > centerX + threshold) {
          return "right";
        } else {
          return "front";
        }
      };

      // Announce important objects and their locations
      window.announceObject = function (
        objectClass,
        confidence,
        direction,
        proximity
      ) {
        // Only announce if confidence is high enough and audio is enabled
        if (confidence < 0.65 || !audioEnabled) return;

        const message = `${objectClass} ${direction}, ${proximity}`;
        window.speakText(message, proximity === "VERY CLOSE!");
      };

      // Play audio from a URL
      window.playAudioFromUrl = function(url) {
        if (!url || !audioEnabled) return;
        
        try {
          // Cancel any ongoing speech
          speechSynthesis.cancel();
          
          // Create audio element
          const audio = new Audio(url);
          
          // Set flag when playback starts
          audio.onplaying = function() {
            geminiAudioPlaying = true;
            console.log("Gemini audio playback started");
          };
          
          // Clear flag when playback ends
          audio.onended = function() {
            geminiAudioPlaying = false;
            console.log("Gemini audio playback completed");
          };
          
          // Handle errors
          audio.onerror = function(e) {
            console.error("Gemini audio playback error:", e);
            geminiAudioPlaying = false;
            
            // Fall back to reading the description using speech synthesis
            if (window.lastGeminiDescription) {
              window.speakText(window.lastGeminiDescription, true);
            }
          };
          
          // Start playback
          audio.play().catch(e => {
            console.error("Error playing Gemini audio:", e);
            geminiAudioPlaying = false;
            
            // Fall back to reading the description using speech synthesis
            if (window.lastGeminiDescription) {
              window.speakText(window.lastGeminiDescription, true);
            }
          });
        } catch (e) {
          console.error("Error setting up Gemini audio playback:", e);
          geminiAudioPlaying = false;
        }
      };
    </script>

    <!-- Camera Preview Helper -->
    <script>
      // Function to update the camera preview with a video stream
      window.updateCameraPreview = function(videoElement) {
        // Find the HTML element with viewType 'camera-preview'
        const findCameraPreview = () => {
          const platformViews = document.querySelectorAll('flt-platform-view');
          for (let i = 0; i < platformViews.length; i++) {
            const view = platformViews[i];
            if (view.dataset.viewType === 'camera-preview') {
              return view;
            }
          }
          return null;
        };

        // Try to find the camera preview element
        const tryAttachCamera = () => {
          const cameraPreview = findCameraPreview();
          if (cameraPreview) {
            // The platform view should already have a video element created by registerViewFactory
            // Replace or update this element with our stream
            const existingVideo = cameraPreview.querySelector('video');
            if (existingVideo) {
              // Replace the video element's source with our stream
              existingVideo.srcObject = videoElement.srcObject;
              existingVideo.play();
              console.log('Camera preview updated with stream');
            } else {
              // If no video element exists, append our video element
              cameraPreview.appendChild(videoElement);
              console.log('Camera preview created with stream');
            }
            return true;
          }
          return false;
        };

        // Try immediately and then retry a few times if needed
        if (!tryAttachCamera()) {
          // Retry a few times with a delay
          let attempts = 0;
          const maxAttempts = 10;
          const interval = setInterval(() => {
            attempts++;
            if (tryAttachCamera() || attempts >= maxAttempts) {
              clearInterval(interval);
              if (attempts >= maxAttempts) {
                console.error('Failed to find camera preview element after', maxAttempts, 'attempts');
              }
            }
          }, 200);
        }
      };
    </script>

    <script>
      // Web Speech API Implementation
      let speechRecognition = null;
      let currentSpeechCallback = null;

      // Function to initialize speech recognition
      function initSpeechRecognition() {
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
          console.error('Speech recognition not supported');
          return false;
        }
        
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        speechRecognition = new SpeechRecognition();
        speechRecognition.continuous = false;
        speechRecognition.interimResults = true;
        speechRecognition.lang = 'en-US';
        
        speechRecognition.onstart = () => {
          console.log('Speech recognition started');
        };
        
        speechRecognition.onerror = (event) => {
          console.error('Speech recognition error:', event.error);
          
          // If callback exists, notify about the error
          if (currentSpeechCallback) {
            currentSpeechCallback(`Error: ${event.error}`, 0);
          }
        };
        
        speechRecognition.onend = () => {
          console.log('Speech recognition ended');
        };
        
        speechRecognition.onresult = (event) => {
          // Get the latest result
          const lastResult = event.results[event.results.length - 1];
          const transcript = lastResult[0].transcript;
          const confidence = lastResult[0].confidence;
          const isFinal = lastResult.isFinal;
          
          console.log('Recognition result:', transcript, 'Confidence:', confidence, 'Final:', isFinal);
          
          // Always call the callback to update UI with partial results
          if (currentSpeechCallback) {
            // For final results, include confidence
            if (isFinal) {
              currentSpeechCallback(transcript, confidence);
            } else {
              // For partial results, send lower confidence to indicate it's not final
              currentSpeechCallback("Hearing: " + transcript, 0.5);
            }
          }
        };
        
        return true;
      }
      
      // Function to start listening for speech
      function startSpeechRecognition(callback) {
        if (!speechRecognition) {
          const initialized = initSpeechRecognition();
          if (!initialized) {
            console.error('Failed to initialize speech recognition');
            return false;
          }
        }
        
        try {
          stopSpeechSynthesis(); // Stop any ongoing speech
          
          currentSpeechCallback = callback;
          speechRecognition.start();
          return true;
        } catch (e) {
          console.error('Error starting speech recognition:', e);
          return false;
        }
      }
      
      // Function to stop listening
      function stopSpeechRecognition() {
        if (speechRecognition) {
          try {
            speechRecognition.stop();
            return true;
          } catch (e) {
            console.error('Error stopping speech recognition:', e);
          }
        }
        return false;
      }
      
      // Text-to-speech synthesis
      let speechSynthesisUtterance = null;
      
      function speakText(text, interrupt = false, rate = 1.0, pitch = 1.0) {
        if (!('speechSynthesis' in window)) {
          console.error('Speech synthesis not supported');
          return false;
        }
        
        if (interrupt) {
          stopSpeechSynthesis();
        }
        
        speechSynthesisUtterance = new SpeechSynthesisUtterance(text);
        speechSynthesisUtterance.rate = rate;
        speechSynthesisUtterance.pitch = pitch;
        speechSynthesisUtterance.onend = () => {
          console.log('Speech synthesis completed');
        };
        
        window.speechSynthesis.speak(speechSynthesisUtterance);
        return true;
      }
      
      function stopSpeechSynthesis() {
        if ('speechSynthesis' in window) {
          window.speechSynthesis.cancel();
        }
      }
      
      // Function to stop Gemini audio
      function stopGeminiAudio() {
        stopSpeechSynthesis();
      }
    </script>

    <script>
      // The value below is injected by flutter build, do not touch.
      var serviceWorkerVersion = "{{flutter_service_worker_version}}";
    </script>
    <!-- This script adds the flutter initialization JS code -->
    <script src="flutter.js" defer></script>
    <script src="google_maps.js" defer></script>
  </head>
  <body>
    <div id="map-container">
      <div id="map"></div>
    </div>
    <div id="flutter_target"></div>
    <script>
      window.addEventListener("load", function (ev) {
        // Download main.dart.js
        _flutter.loader.loadEntrypoint({
          serviceWorker: {
            serviceWorkerVersion: serviceWorkerVersion,
          },
          onEntrypointLoaded: function (engineInitializer) {
            engineInitializer.initializeEngine().then(function (appRunner) {
              appRunner.runApp();
            });
          },
        });
      });
    </script>
  </body>
</html>
