<!DOCTYPE html>
<html>
  <head>
    <base href="/" />

    <meta charset="UTF-8" />
    <meta content="IE=Edge" http-equiv="X-UA-Compatible" />
    <meta name="description" content="A visual assistance application" />

    <!-- iOS meta tags & icons -->
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="apple-mobile-web-app-title" content="vision_assist" />
    <link rel="apple-touch-icon" href="icons/Icon-192.png" />

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="favicon.png" />

    <title>Vision Assist</title>
    <link rel="manifest" href="manifest.json" />

    <!-- Load TensorFlow.js and COCO-SSD model before the Flutter-related scripts -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="object_detector.js"></script>

    <!-- Audio feedback helper -->
    <script>
      // Text-to-speech utility
      const speechSynthesis = window.speechSynthesis;
      let speakingQueue = [];
      let isSpeaking = false;
      let audioEnabled = true;
      let geminiAudioPlaying = false;

      // Toggle audio on/off
      window.toggleAudio = function (enabled) {
        audioEnabled = enabled;

        if (!enabled) {
          // Cancel any ongoing speech
          speechSynthesis.cancel();
          speakingQueue = [];
          isSpeaking = false;
          geminiAudioPlaying = false;
        } else {
          // Announce that audio is enabled
          window.speakText("Audio feedback enabled", true);
        }
      };

      // Check if Gemini audio is currently playing
      window.isGeminiAudioPlaying = function() {
        return geminiAudioPlaying;
      };

      // Speak text with specified options
      window.speakText = function (
        text,
        priority = false,
        rate = 1.0,
        pitch = 1.0
      ) {
        if (!text || !audioEnabled) return;

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = rate;
        utterance.pitch = pitch;
        
        // Use a more natural voice if available
        try {
          const voices = speechSynthesis.getVoices();
          // Try to find a good quality female voice
          const preferredVoices = [
            "Google US English Female",
            "Microsoft Zira - English (United States)",
            "Samantha",
            "Karen"
          ];
          
          let selectedVoice = null;
          
          // First try to find one of our preferred voices
          for (const prefVoice of preferredVoices) {
            selectedVoice = voices.find(v => v.name === prefVoice);
            if (selectedVoice) break;
          }
          
          // If no preferred voice found, try to find any female US English voice
          if (!selectedVoice) {
            selectedVoice = voices.find(v => 
              v.name.includes("Female") && 
              (v.lang === "en-US" || v.lang === "en_US")
            );
          }
          
          // If we found a better voice, use it
          if (selectedVoice) {
            utterance.voice = selectedVoice;
          }
        } catch (e) {
          console.log("Error setting voice:", e);
        }

        // If priority message, cancel current speech and speak immediately
        if (priority) {
          speechSynthesis.cancel();
          speakingQueue = [];
          speechSynthesis.speak(utterance);
          return;
        }

        // Add to queue
        speakingQueue.push(utterance);

        // Process queue if not already speaking
        if (!isSpeaking) {
          processQueue();
        }
      };

      // Process the speaking queue
      function processQueue() {
        if (speakingQueue.length === 0) {
          isSpeaking = false;
          return;
        }

        isSpeaking = true;
        const utterance = speakingQueue.shift();

        utterance.onend = () => {
          setTimeout(() => processQueue(), 100); // Small delay between messages
        };

        speechSynthesis.speak(utterance);
      }

      // Get direction relative to camera center (left, right, center)
      window.getRelativeDirection = function (objectX, frameWidth) {
        const centerX = frameWidth / 2;
        const threshold = frameWidth * 0.2; // 20% of frame width

        if (objectX < centerX - threshold) {
          return "left";
        } else if (objectX > centerX + threshold) {
          return "right";
        } else {
          return "front";
        }
      };

      // Announce important objects and their locations
      window.announceObject = function (
        objectClass,
        confidence,
        direction,
        proximity
      ) {
        // Only announce if confidence is high enough and audio is enabled
        if (confidence < 0.65 || !audioEnabled) return;

        const message = `${objectClass} ${direction}, ${proximity}`;
        window.speakText(message, proximity === "VERY CLOSE!");
      };

      // Play audio from base64 string
      window.playAudioFromBase64 = function(base64String) {
        if (!base64String || !audioEnabled) return;
        
        try {
          // Cancel any ongoing speech
          speechSynthesis.cancel();
          
          // Create audio from the base64 string
          const audio = new Audio(`data:audio/mp3;base64,${base64String}`);
          
          // Set up audio event listeners
          geminiAudioPlaying = true;
          
          audio.onended = function() {
            geminiAudioPlaying = false;
            console.log("Gemini audio playback completed");
          };
          
          audio.onerror = function() {
            geminiAudioPlaying = false;
            console.error("Error in Gemini audio playback");
          };
          
          // Play the audio
          audio.play().catch(error => {
            console.error('Error playing audio:', error);
            geminiAudioPlaying = false;
          });
        } catch (error) {
          console.error('Error creating audio from base64:', error);
          geminiAudioPlaying = false;
        }
      };
      
      // Play audio from a data URL
      window.playAudioFromUrl = function(audioUrl) {
        if (!audioUrl || !audioEnabled) return;
        
        try {
          // Cancel any ongoing speech
          speechSynthesis.cancel();
          
          // Create and play audio from URL
          const audio = new Audio(audioUrl);
          
          // Set up audio event listeners
          geminiAudioPlaying = true;
          
          audio.onended = function() {
            geminiAudioPlaying = false;
            console.log("Gemini audio playback completed");
          };
          
          audio.onerror = function() {
            geminiAudioPlaying = false;
            console.error("Error in Gemini audio playback");
          };
          
          // Play the audio
          audio.play().catch(error => {
            console.error('Error playing audio from URL:', error);
            geminiAudioPlaying = false;
            
            // If playback fails, try to extract the base64 content
            if (audioUrl.startsWith('data:audio/mp3;base64,')) {
              const base64Data = audioUrl.split(',')[1];
              if (base64Data) {
                window.playAudioFromBase64(base64Data);
              }
            }
          });
        } catch (error) {
          console.error('Error playing audio from URL:', error);
          geminiAudioPlaying = false;
        }
      };
    </script>

    <!-- Camera Preview Helper -->
    <script>
      // Function to update the camera preview with a video stream
      window.updateCameraPreview = function(videoElement) {
        // Find the HTML element with viewType 'camera-preview'
        const findCameraPreview = () => {
          const platformViews = document.querySelectorAll('flt-platform-view');
          for (let i = 0; i < platformViews.length; i++) {
            const view = platformViews[i];
            if (view.dataset.viewType === 'camera-preview') {
              return view;
            }
          }
          return null;
        };

        // Try to find the camera preview element
        const tryAttachCamera = () => {
          const cameraPreview = findCameraPreview();
          if (cameraPreview) {
            // The platform view should already have a video element created by registerViewFactory
            // Replace or update this element with our stream
            const existingVideo = cameraPreview.querySelector('video');
            if (existingVideo) {
              // Replace the video element's source with our stream
              existingVideo.srcObject = videoElement.srcObject;
              existingVideo.play();
              console.log('Camera preview updated with stream');
            } else {
              // If no video element exists, append our video element
              cameraPreview.appendChild(videoElement);
              console.log('Camera preview created with stream');
            }
            return true;
          }
          return false;
        };

        // Try immediately and then retry a few times if needed
        if (!tryAttachCamera()) {
          // Retry a few times with a delay
          let attempts = 0;
          const maxAttempts = 10;
          const interval = setInterval(() => {
            attempts++;
            if (tryAttachCamera() || attempts >= maxAttempts) {
              clearInterval(interval);
              if (attempts >= maxAttempts) {
                console.error('Failed to find camera preview element after', maxAttempts, 'attempts');
              }
            }
          }, 200);
        }
      };
    </script>

    <script>
      // The value below is injected by flutter build, do not touch.
      var serviceWorkerVersion = "{{flutter_service_worker_version}}";
    </script>
    <!-- This script adds the flutter initialization JS code -->
    <script src="flutter.js" defer></script>
  </head>
  <body>
    <script>
      window.addEventListener("load", function (ev) {
        // Download main.dart.js
        _flutter.loader.loadEntrypoint({
          serviceWorker: {
            serviceWorkerVersion: serviceWorkerVersion,
          },
          onEntrypointLoaded: function (engineInitializer) {
            engineInitializer.initializeEngine().then(function (appRunner) {
              appRunner.runApp();
            });
          },
        });
      });
    </script>
  </body>
</html>
